{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 : Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_politics = 'https://www.reddit.com/r/politics.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_sports = 'https://www.reddit.com/r/sports.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent': 'Naoufal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_politics = requests.get(url_politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sports = requests.get(url_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(res_politics)\n",
    "print(res_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_politics_content = res_politics.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sports_content = res_sports.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_politics_json = res_politics.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sports_json = res_sports.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_politics_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sports_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['modhash', 'dist', 'children', 'after', 'before'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_politics_json['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['modhash', 'dist', 'children', 'after', 'before'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sports_json['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_di9dad',\n",
       " 't3_digrkk',\n",
       " 't3_dieoev',\n",
       " 't3_difal4',\n",
       " 't3_difeo0',\n",
       " 't3_did11u',\n",
       " 't3_dicaua',\n",
       " 't3_die835',\n",
       " 't3_dibasd',\n",
       " 't3_dia959',\n",
       " 't3_dib583',\n",
       " 't3_dihnvu',\n",
       " 't3_didwpl',\n",
       " 't3_diexor',\n",
       " 't3_dib7h8',\n",
       " 't3_difnkx',\n",
       " 't3_di9u7q',\n",
       " 't3_did94d',\n",
       " 't3_di9bhy',\n",
       " 't3_dibgdo',\n",
       " 't3_di879i',\n",
       " 't3_di8hku',\n",
       " 't3_di7ph3',\n",
       " 't3_diavxs',\n",
       " 't3_die7ak',\n",
       " 't3_digsdd',\n",
       " 't3_difdac']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[post['data']['name'] for post in res_politics_json['data']['children']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_di8fwt',\n",
       " 't3_di3qq7',\n",
       " 't3_difamf',\n",
       " 't3_dicjp2',\n",
       " 't3_dicv47',\n",
       " 't3_dihy49',\n",
       " 't3_dhtfzp',\n",
       " 't3_di6pgw',\n",
       " 't3_difruh',\n",
       " 't3_di0xcu',\n",
       " 't3_diaj27',\n",
       " 't3_diixes',\n",
       " 't3_di9noe',\n",
       " 't3_di855c',\n",
       " 't3_dhz76e',\n",
       " 't3_di6fuc',\n",
       " 't3_diiex8',\n",
       " 't3_dhi4sd',\n",
       " 't3_dibb2o',\n",
       " 't3_di1zbz',\n",
       " 't3_dhzllc',\n",
       " 't3_dhwqgn',\n",
       " 't3_dh9lgu',\n",
       " 't3_dhzg1d',\n",
       " 't3_dhocg5']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[post['data']['name'] for post in res_sports_json['data']['children']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_difdac'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_politics_json['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_dhocg5'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sports_json['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_params = {'after': res_politics_json['data']['after']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_params = {'after': res_sports_json['data']['after']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "jsons_politics =[]\n",
    "after = None\n",
    "for i in range (40):\n",
    "    print(i)\n",
    "    if after ==None:\n",
    "        politics_params = {}\n",
    "    else:\n",
    "        politics_params = {'after': after}\n",
    "        \n",
    "    url_politics = 'https://www.reddit.com/r/politics.json'\n",
    "    res_politics_2 = requests.get(url_politics, params=politics_params, headers=headers)\n",
    "    \n",
    "    if res_politics_2.status_code ==200:\n",
    "        res_politics_json = res_politics_2.json()\n",
    "        jsons_politics.extend(res_politics_json['data']['children'])\n",
    "        after = res_politics_json['data']['after']\n",
    "        \n",
    "    else:\n",
    "        print(res_politics_2.status_code)\n",
    "        break\n",
    "        \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "jsons_sports =[]\n",
    "after = None\n",
    "for i in range (40):\n",
    "    print(i)\n",
    "    if after ==None:\n",
    "        sports_params = {}\n",
    "    else:\n",
    "        sports_params = {'after': after}\n",
    "        \n",
    "    url_sports = 'https://www.reddit.com/r/sports.json'\n",
    "    res_sports_2 = requests.get(url_sports, params=sports_params, headers=headers)\n",
    "    \n",
    "    if res_sports_2.status_code ==200:\n",
    "        res_sports_json = res_sports_2.json()\n",
    "        jsons_sports.extend(res_sports_json['data']['children'])\n",
    "        after = res_sports_json['data']['after']\n",
    "        \n",
    "    else:\n",
    "        print(res_psports_2.status_code)\n",
    "        break\n",
    "        \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jsons_politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([p['data']['name'] for p in jsons_politics]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jsons_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([p['data']['name'] for p in jsons_sports]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_politics[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_sports[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Dict to DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politics = pd.DataFrame(jsons_politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, 2)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kind                                               data\n",
       "0   t3  {'approved_at_utc': None, 'subreddit': 'politi...\n",
       "1   t3  {'approved_at_utc': None, 'subreddit': 'politi...\n",
       "2   t3  {'approved_at_utc': None, 'subreddit': 'politi...\n",
       "3   t3  {'approved_at_utc': None, 'subreddit': 'politi...\n",
       "4   t3  {'approved_at_utc': None, 'subreddit': 'politi..."
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politics = pd.DataFrame(df_politics['data'].values.tolist(), index=df_politics.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, 109)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sports = pd.DataFrame(jsons_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'sports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'sports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'sports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'sports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>t3</td>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'sports...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kind                                               data\n",
       "0   t3  {'approved_at_utc': None, 'subreddit': 'sports...\n",
       "1   t3  {'approved_at_utc': None, 'subreddit': 'sports...\n",
       "2   t3  {'approved_at_utc': None, 'subreddit': 'sports...\n",
       "3   t3  {'approved_at_utc': None, 'subreddit': 'sports...\n",
       "4   t3  {'approved_at_utc': None, 'subreddit': 'sports..."
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sports = pd.DataFrame(df_sports['data'].values.tolist(), index=df_sports.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 105)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 4255)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging & Cleaning DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politics['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sports['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoufal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat((df_politics, df_sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    We are leaders at NALEO Educational Fund. We’r...\n",
       "1    Discussion Thread: Fourth Democratic President...\n",
       "2    'Arrest and Detain Giuliani Right Now,' Say Cr...\n",
       "3    Pence refuses House request to provide documen...\n",
       "4    Erdogan tells Trump that Turkey will 'never de...\n",
       "5    RNC Chairwoman Decries Nepotism In Politics — ...\n",
       "6    Giuliani says he won't comply with a congressi...\n",
       "7    The floodgates are opening as Trump officials ...\n",
       "8    Giuliani pressed Trump to eject Muslim cleric ...\n",
       "9    New Poll Suggests Sen. Susan Collins’ Support ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_politics_sports.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1961, 110)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined']=df.apply(lambda x:'%s_%s' % (x['title'],x['selftext']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined'] = df['combined'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We are leaders at NALEO Educational Fund. We’r...</td>\n",
       "      <td>Hi Reddit! We are Arturo Vargas, CEO and Lizet...</td>\n",
       "      <td>we are leaders at naleo educational fund. we’r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Discussion Thread: Fourth Democratic President...</td>\n",
       "      <td>This is the \"post-debate\" thread for the fourt...</td>\n",
       "      <td>discussion thread: fourth democratic president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>'Arrest and Detain Giuliani Right Now,' Say Cr...</td>\n",
       "      <td></td>\n",
       "      <td>'arrest and detain giuliani right now,' say cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Pence refuses House request to provide documen...</td>\n",
       "      <td></td>\n",
       "      <td>pence refuses house request to provide documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Erdogan tells Trump that Turkey will 'never de...</td>\n",
       "      <td></td>\n",
       "      <td>erdogan tells trump that turkey will 'never de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>Unbelievable catch by Jonathan Carter in the CPL</td>\n",
       "      <td></td>\n",
       "      <td>unbelievable catch by jonathan carter in the cpl_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>1</td>\n",
       "      <td>High school running back gets flipped over and...</td>\n",
       "      <td></td>\n",
       "      <td>high school running back gets flipped over and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>Youth sports officials and referees quitting a...</td>\n",
       "      <td></td>\n",
       "      <td>youth sports officials and referees quitting a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>1</td>\n",
       "      <td>Essex's captain Simon Harmer lifts the Vitalit...</td>\n",
       "      <td></td>\n",
       "      <td>essex's captain simon harmer lifts the vitalit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>977</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia v Fiji (39-21) | Rugby World Cup 2019</td>\n",
       "      <td></td>\n",
       "      <td>australia v fiji (39-21) | rugby world cup 2019_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1961 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                              title  \\\n",
       "0        0  We are leaders at NALEO Educational Fund. We’r...   \n",
       "1        0  Discussion Thread: Fourth Democratic President...   \n",
       "2        0  'Arrest and Detain Giuliani Right Now,' Say Cr...   \n",
       "3        0  Pence refuses House request to provide documen...   \n",
       "4        0  Erdogan tells Trump that Turkey will 'never de...   \n",
       "..     ...                                                ...   \n",
       "973      1   Unbelievable catch by Jonathan Carter in the CPL   \n",
       "974      1  High school running back gets flipped over and...   \n",
       "975      1  Youth sports officials and referees quitting a...   \n",
       "976      1  Essex's captain Simon Harmer lifts the Vitalit...   \n",
       "977      1    Australia v Fiji (39-21) | Rugby World Cup 2019   \n",
       "\n",
       "                                              selftext  \\\n",
       "0    Hi Reddit! We are Arturo Vargas, CEO and Lizet...   \n",
       "1    This is the \"post-debate\" thread for the fourt...   \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "973                                                      \n",
       "974                                                      \n",
       "975                                                      \n",
       "976                                                      \n",
       "977                                                      \n",
       "\n",
       "                                              combined  \n",
       "0    we are leaders at naleo educational fund. we’r...  \n",
       "1    discussion thread: fourth democratic president...  \n",
       "2    'arrest and detain giuliani right now,' say cr...  \n",
       "3    pence refuses house request to provide documen...  \n",
       "4    erdogan tells trump that turkey will 'never de...  \n",
       "..                                                 ...  \n",
       "973  unbelievable catch by jonathan carter in the cpl_  \n",
       "974  high school running back gets flipped over and...  \n",
       "975  youth sports officials and referees quitting a...  \n",
       "976  essex's captain simon harmer lifts the vitalit...  \n",
       "977   australia v fiji (39-21) | rugby world cup 2019_  \n",
       "\n",
       "[1961 rows x 4 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['label', 'title', 'selftext', 'combined']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df['combined']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    983\n",
       "1    978\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cvec.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 4255)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000m</th>\n",
       "      <th>00_</th>\n",
       "      <th>04</th>\n",
       "      <th>041lbs</th>\n",
       "      <th>04_</th>\n",
       "      <th>0_</th>\n",
       "      <th>10</th>\n",
       "      <th>1000</th>\n",
       "      <th>1000_</th>\n",
       "      <th>...</th>\n",
       "      <th>yu</th>\n",
       "      <th>yun</th>\n",
       "      <th>zdenrk</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealands</th>\n",
       "      <th>zhiyong</th>\n",
       "      <th>zone_</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerberg_</th>\n",
       "      <th>zuerlein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 4255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  000m  00_  04  041lbs  04_  0_  10  1000  1000_  ...  yu  yun  \\\n",
       "0       0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "1       0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "2       0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "3       0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "4       0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "...   ...   ...  ...  ..     ...  ...  ..  ..   ...    ...  ...  ..  ...   \n",
       "1308    0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "1309    0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "1310    0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "1311    0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "1312    0     0    0   0       0    0   0   0     0      0  ...   0    0   \n",
       "\n",
       "      zdenrk  zealand  zealands  zhiyong  zone_  zuckerberg  zuckerberg_  \\\n",
       "0          0        0         0        0      0           0            0   \n",
       "1          0        0         0        0      0           0            0   \n",
       "2          0        0         0        0      1           0            0   \n",
       "3          0        0         0        0      0           0            0   \n",
       "4          0        0         0        0      0           0            0   \n",
       "...      ...      ...       ...      ...    ...         ...          ...   \n",
       "1308       0        0         0        0      0           0            0   \n",
       "1309       0        0         0        0      0           0            0   \n",
       "1310       0        0         0        0      0           0            0   \n",
       "1311       0        0         0        0      0           0            0   \n",
       "1312       0        0         0        0      0           0            0   \n",
       "\n",
       "      zuerlein  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "1308         0  \n",
       "1309         0  \n",
       "1310         0  \n",
       "1311         0  \n",
       "1312         0  \n",
       "\n",
       "[1313 rows x 4255 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame(X_train.toarray(),\n",
    "                          columns=cvec.get_feature_names())\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x4255 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 50 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cvec.transform(X_test)\n",
    "X_test_df = pd.DataFrame(X_test.toarray(),\n",
    "                         columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'keep', 'latter', 'herself', 'most', 'nevertheless', 'please', 'further', 'per', 'whereafter', 'none', 'next', 'this', 'twelve', 'until', 'amount', 'becomes', 'once', 'mine', 'that', 'any', 'eg', 'back', 'less', 'now', 'somewhere', 'namely', 'via', 'find', 'myself', 'below', 'formerly', 'go', 'meanwhile', 'others', 'might', 'detail', 'whereby', 'who', 'interest', 'seems', 'system', 'on', 'were', 'empty', 'into', 'front', 'my', 'moreover', 'see', 'amongst', 'top', 'besides', 'is', 'through', 'hereafter', 'hundred', 'still', 'almost', 'along', 'due', 'too', 'will', 'whose', 'are', 'beyond', 'or', 'throughout', 'also', 'get', 'co', 'whence', 'sincere', 'last', 'yourselves', 'here', 'twenty', 'then', 'except', 'whereas', 'hereupon', 'least', 'we', 'why', 'before', 'beforehand', 'her', 'hers', 'has', 'ten', 'four', 'noone', 'serious', 'whither', 'would', 'him', 'un', 'two', 'which', 'by', 'etc', 'neither', 'nowhere', 'over', 'such', 'whom', 'ours', 'of', 'somehow', 'afterwards', 'already', 'wherever', 'made', 'to', 'it', 'nor', 'if', 'otherwise', 'should', 'found', 'side', 'these', 'very', 'during', 'among', 'fill', 'how', 'them', 'there', 'no', 'thereupon', 'was', 'yours', 'couldnt', 'cannot', 'same', 'someone', 'although', 'i', 'for', 'whatever', 'must', 'within', 'describe', 'wherein', 'not', 'however', 'themselves', 'fifty', 'behind', 'part', 'us', 'anyone', 'de', 'ltd', 'ourselves', 'can', 'since', 'thus', 'together', 'been', 'fifteen', 'amoungst', 'be', 'both', 'may', 'off', 'perhaps', 'the', 'always', 'every', 'ie', 'five', 'their', 'your', 'a', 'and', 'few', 'thence', 'eleven', 'am', 'its', 'with', 'hereby', 'sometimes', 'thru', 'yourself', 'some', 'anyway', 'never', 'onto', 'sixty', 'something', 'itself', 'toward', 'what', 'latterly', 'anything', 'up', 'ever', 'whether', 'seem', 'thereby', 'even', 'hence', 'name', 'six', 'without', 'while', 'many', 'where', 'she', 'those', 'because', 'eight', 'though', 'mill', 'everyone', 'more', 'three', 'have', 'indeed', 'herein', 'nobody', 'bill', 'give', 'often', 'than', 'an', 'upon', 'when', 'several', 'under', 'against', 'all', 'he', 'out', 'nothing', 'in', 'rather', 'around', 'inc', 'thereafter', 'thin', 'whoever', 'con', 'else', 'cant', 'everything', 'third', 'whole', 'first', 'after', 'well', 'between', 'you', 'whenever', 'former', 'do', 'fire', 'had', 'could', 'seeming', 'hasnt', 'elsewhere', 'anyhow', 'enough', 'being', 'alone', 'much', 'call', 'himself', 'other', 'own', 'either', 'so', 'at', 'again', 'his', 'only', 'each', 'across', 'seemed', 'full', 'forty', 'therein', 'thick', 'put', 'cry', 'one', 'everywhere', 'became', 'become', 'becoming', 'take', 'above', 'but', 'they', 'nine', 'sometime', 'yet', 'done', 'down', 'therefore', 'move', 'another', 'mostly', 'our', 'towards', 're', 'show', 'beside', 'from', 'anywhere', 'as', 'whereupon', 'me', 'bottom', 'about'})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.501543\n",
       "1    0.498457\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params, \n",
    "                  cv=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2500, 3000, 3500], 'cvec__min_df': [1, 2], 'cvec__max_df': [0.9, 0.95], 'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964965727341965\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992383853769993"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000m</th>\n",
       "      <th>00_</th>\n",
       "      <th>04</th>\n",
       "      <th>041lbs</th>\n",
       "      <th>04_</th>\n",
       "      <th>0_</th>\n",
       "      <th>10</th>\n",
       "      <th>1000</th>\n",
       "      <th>1000_</th>\n",
       "      <th>...</th>\n",
       "      <th>yu</th>\n",
       "      <th>yun</th>\n",
       "      <th>zdenrk</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealands</th>\n",
       "      <th>zhiyong</th>\n",
       "      <th>zone_</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerberg_</th>\n",
       "      <th>zuerlein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000m  00_   04  041lbs  04_   0_   10  1000  1000_  ...   yu  yun  \\\n",
       "0  0.0   0.0  0.0  0.0     0.0  0.0  0.0  0.0   0.0    0.0  ...  0.0  0.0   \n",
       "1  0.0   0.0  0.0  0.0     0.0  0.0  0.0  0.0   0.0    0.0  ...  0.0  0.0   \n",
       "2  0.0   0.0  0.0  0.0     0.0  0.0  0.0  0.0   0.0    0.0  ...  0.0  0.0   \n",
       "3  0.0   0.0  0.0  0.0     0.0  0.0  0.0  0.0   0.0    0.0  ...  0.0  0.0   \n",
       "4  0.0   0.0  0.0  0.0     0.0  0.0  0.0  0.0   0.0    0.0  ...  0.0  0.0   \n",
       "\n",
       "   zdenrk  zealand  zealands  zhiyong     zone_  zuckerberg  zuckerberg_  \\\n",
       "0     0.0      0.0       0.0      0.0  0.000000         0.0          0.0   \n",
       "1     0.0      0.0       0.0      0.0  0.000000         0.0          0.0   \n",
       "2     0.0      0.0       0.0      0.0  0.401602         0.0          0.0   \n",
       "3     0.0      0.0       0.0      0.0  0.000000         0.0          0.0   \n",
       "4     0.0      0.0       0.0      0.0  0.000000         0.0          0.0   \n",
       "\n",
       "   zuerlein  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 4255 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tvec.fit_transform(X_train).toarray(),\n",
    "                  columns=tvec.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tvec.fit_transform(X_train)\n",
    "\n",
    "X_test = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9977151561309977\n",
      "Testing Score: 0.9768518518518519\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f'Training Score: {lr.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Coefficient: [[-0.29949879  0.17422428  0.13554683 ... -0.39221971 -0.10265872\n",
      "   0.12419944]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Logistic Regression Coefficient: {lr.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74118962, 1.19032251, 1.14516283, ..., 0.67555567, 0.90243491,\n",
       "        1.13224166]])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
